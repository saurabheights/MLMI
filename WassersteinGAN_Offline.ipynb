{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from tensorflow import summary\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import logger\n",
    "from utils import tensorboard_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5], std=[0.5])\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "    out_dir = './dataset'\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "# Load data\n",
    "data = mnist_data()\n",
    "# Create loader with data, so that we can iterate over it\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=64, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(data_loader)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = 784\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "#             torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "discriminator = DiscriminatorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100\n",
    "        n_out = 784\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "generator = GeneratorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    '''\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    '''\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = optim.RMSprop(discriminator.parameters(), lr=5e-5)\n",
    "g_optimizer = optim.RMSprop(generator.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    N = real_data.size(0)\n",
    "    # Reset gradients\n",
    "    d_optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "#     error_real = loss(prediction_real, ones_target(N) )\n",
    "#     error_real.backward()\n",
    "#     prediction_real = Variable(prediction_real, requires_grad=True)\n",
    "    D_loss_real = -(torch.mean(real_data) - torch.mean(prediction_real))\n",
    "    D_loss_real = Variable(D_loss_real, requires_grad=True)\n",
    "    D_loss_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "#     prediction_fake = Variable(prediction_fake, requires_grad=True)\n",
    "    # Calculate error and backpropagate\n",
    "#     error_fake = loss(prediction_fake, zeros_target(N))\n",
    "#     error_fake.backward()\n",
    "    D_loss_fake = -(torch.mean(fake_data) - torch.mean(prediction_fake))\n",
    "    D_loss_fake = Variable(D_loss_fake, requires_grad=True)\n",
    "    D_loss_fake.backward()\n",
    "\n",
    "    \n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "#     optimizer.step()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    for p in discriminator.parameters():\n",
    "        p.data.clamp_(-0.01, 0.01)\n",
    "    \n",
    "    # Return error and predictions for real and fake inputs\n",
    "    return D_loss_real + D_loss_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer, fake_data):\n",
    "    N = fake_data.size(0)\n",
    "    # Reset gradients\n",
    "    g_optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    G_loss = -torch.mean(prediction)\n",
    "    G_loss = Variable(G_loss, requires_grad=True)\n",
    "    G_loss.backward()\n",
    "#     error = loss(prediction, ones_target(N))\n",
    "    # Update weights with gradients\n",
    "    g_optimizer.step()\n",
    "    # Return error\n",
    "    return G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger instance\n",
    "# logger = utils.Logger(model_name='VGAN', data_name='MNIST')\n",
    "logger_obj = logger.init('utils/runs')\n",
    "writer = tensorboard_writer.TensorboardWriter('utils/runs/')\n",
    "current_time = str(datetime.datetime.now().timestamp())\n",
    "train_log_dir = 'utils/runs/' + current_time\n",
    "train_summary_writer = summary.FileWriter(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdaced04240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir utils/runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 19:03:43,218 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,227 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,231 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,234 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,236 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,238 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,241 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,243 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,245 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,248 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,250 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,252 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,255 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,256 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,258 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,260 |     MainProcess | MainThread | Summary name Real Images is illegal; using Real_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,261 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,263 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,265 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,267 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,268 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,270 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,272 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,274 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,276 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,278 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,281 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,283 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,285 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,287 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,290 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n",
      "2019-11-27 19:03:43,292 |     MainProcess | MainThread | Summary name Fake Images is illegal; using Fake_Images instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-125f6705726d>\", line 27, in <module>\n",
      "    logger.info(title,d_error, g_error, epoch, n_batch, num_batches)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/MLMI/utils/logger.py\", line 55, in info\n",
      "    logging.info(message, *args)\n",
      "Message: 'INFO  | <ipython-input-15-125f6705726d>::<module>():27     | Epoch:0'\n",
      "Arguments: (tensor(0.7298, grad_fn=<AddBackward0>), tensor(0.0087, requires_grad=True), 0, 0, 938)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/MLMI/utils/ColoredFormatter.py\", line 168, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/saosurvivor/Projects/MLMI/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-125f6705726d>\", line 27, in <module>\n",
      "    logger.info(title,d_error, g_error, epoch, n_batch, num_batches)\n",
      "  File \"/home/saosurvivor/Projects/MLMI/MLMI/utils/logger.py\", line 55, in info\n",
      "    logging.info(message, *args)\n",
      "Message: 'INFO  | <ipython-input-15-125f6705726d>::<module>():27     | Epoch:0'\n",
      "Arguments: (tensor(0.7298, grad_fn=<AddBackward0>), tensor(0.0087, requires_grad=True), 0, 0, 938)\n"
     ]
    },
   "source": [
    "# Create logger instance\n",
    "# logger = utils.Logger(model_name='VGAN', data_name='MNIST')\n",
    "# logger_obj = logger.init('utils/runs')\n",
    "# writer = tensorboard_writer.TensorboardWriter('utils/runs/')\n",
    "# Total number of epochs to train\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
    "        N = real_batch.size(0)\n",
    "        for _ in range(5):\n",
    "            # 1. Train Discriminator\n",
    "            real_data = Variable(images_to_vectors(real_batch))\n",
    "            # Generate fake data and detach \n",
    "            # (so gradients are not calculated for generator)\n",
    "            fake_data = generator(noise(N)).detach()\n",
    "            # Train D\n",
    "            d_error, d_pred_real, d_pred_fake = \\\n",
    "                  train_discriminator(d_optimizer, real_data, fake_data)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(N))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "        # Log batch error\n",
    "        title = \"Epoch:\" + str(epoch)\n",
    "        logger.info(title,d_error, g_error, epoch, n_batch, num_batches)\n",
    "        # Display Progress every few batches\n",
    "        if (n_batch) % 100 == 0: \n",
    "            test_images = vectors_to_images(generator(test_noise))\n",
    "            test_images = test_images.data\n",
    "            for image in test_images:\n",
    "                writer.save_image(\"Real Images\",\n",
    "                vutils.make_grid(test_images[0][:64], padding=5, normalize=True)\n",
    "                );\n",
    "            fake_images = vectors_to_images(fake_data)\n",
    "            fake_images = fake_images.data\n",
    "            for image in test_images:\n",
    "                writer.save_image(\"Fake Images\",\n",
    "                vutils.make_grid(fake_images[0][:64], padding=5, normalize=True)\n",
    "                );\n",
    "#                 writer.save_image(\"Generated Images\", \n",
    "#                                   vecotors\n",
    "#                 );\n",
    "            with train_summary_writer.__enter__():\n",
    "                tf.summary.scalar('G_loss', g_error.detach())\n",
    "                tf.summary.scalar('D_loss', d_error.detach())\n",
    "            # Display status Logs\n",
    "#             logger.display_status(\n",
    "#                 epoch, num_epochs, n_batch, num_batches,\n",
    "#                 d_error, g_error, d_pred_real, d_pred_fake\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
